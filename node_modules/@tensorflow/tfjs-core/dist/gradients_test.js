"use strict";
/**
 * @license
 * Copyright 2019 Google Inc. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 * =============================================================================
 */
Object.defineProperty(exports, "__esModule", { value: true });
var engine_1 = require("./engine");
var tf = require("./index");
var jasmine_util_1 = require("./jasmine_util");
var test_util_1 = require("./test_util");
jasmine_util_1.describeWithFlags('gradients', jasmine_util_1.ALL_ENVS, function () {
    it('matmul + relu', function () {
        var a = tf.tensor2d([-1, 2, -3, 10, -20, 30], [2, 3]);
        var b = tf.tensor2d([2, -3, 4, -1, 2, -3], [3, 2]);
        var _a = tf.grads(function (a, b) {
            // m = dot(a, b)
            // y = relu(m)
            // e = sum(y)
            var m = tf.matMul(a, b);
            var y = tf.relu(m);
            return tf.sum(y);
        })([a, b]), da = _a[0], db = _a[1];
        // de/dy = 1
        // dy/dm = step(m)
        // de/dm = de/dy * dy/dm = step(m)
        var dedm = tf.step(tf.matMul(a, b));
        // de/da = dot(de/dy, bT)
        expect(da.shape).toEqual(a.shape);
        var transposeA = false;
        var transposeB = true;
        test_util_1.expectArraysClose(da, tf.matMul(dedm, b, transposeA, transposeB));
        // de/db = dot(aT, de/dy)
        expect(db.shape).toEqual(b.shape);
        transposeA = true;
        transposeB = false;
        test_util_1.expectArraysClose(db, tf.matMul(a, dedm, transposeA, transposeB));
    });
    it('grad(f)', function () {
        var grad = tf.grad(function (x) { return x.square(); });
        var result = grad(tf.tensor1d([.1, .2]));
        test_util_1.expectArraysClose(result, [.2, .4]);
    });
    it('calling grad(f) twice works', function () {
        var grad = tf.grad(function (x) { return x.square(); });
        var result = grad(tf.tensor1d([.1, .2]));
        var result2 = grad(tf.tensor1d([.1, .4]));
        test_util_1.expectArraysClose(result, [.2, .4]);
        test_util_1.expectArraysClose(result2, [.2, .8]);
    });
    it('grad(f): throwing an error during forward pass', function () {
        var grad = tf.grad(function (x) {
            throw new Error('failed forward pass');
        });
        expect(function () { return grad(tf.zeros([])); }).toThrowError();
        expect(engine_1.ENGINE.isTapeOn()).toBe(false);
    });
    it('grad(f): throwing an error during backwards pass', function () {
        var customOp = tf.customGrad(function (x) {
            return {
                value: x,
                gradFunc: function () {
                    throw new Error('failed backward pass');
                }
            };
        });
        var grad = tf.grad(function (x) { return customOp(x); });
        expect(function () { return grad(tf.zeros([])); }).toThrowError();
        expect(engine_1.ENGINE.isTapeOn()).toBe(false);
    });
    it('grads(f)', function () {
        var grads = tf.grads(function (x) { return x.square(); });
        var result = grads([tf.tensor1d([.1, .2])]);
        test_util_1.expectArraysClose(result[0], [.2, .4]);
    });
    it('calling grads(f) twice works', function () {
        var grads = tf.grads(function (x) { return x.square(); });
        var result = grads([tf.tensor1d([.1, .2])]);
        var result2 = grads([tf.tensor1d([.1, .4])]);
        test_util_1.expectArraysClose(result[0], [.2, .4]);
        test_util_1.expectArraysClose(result2[0], [.2, .8]);
    });
    it('works with reshape', function () {
        var a = tf.tensor2d([1, 2, 3, 4], [2, 2]);
        var exponent = tf.tensor1d([2, 2, 2, 2], 'int32');
        var da = tf.grad(function (a) {
            var b = a.flatten();
            var m = tf.pow(b, exponent);
            return tf.sum(m);
        })(a);
        expect(da.shape).toEqual([2, 2]);
        test_util_1.expectArraysClose(da, [2, 4, 6, 8]);
    });
    it('reshape outside tf.grads() throws error', function () {
        var a = tf.tensor2d([1, 2, 3, 4], [2, 2]);
        var b = a.flatten();
        var exponent = tf.tensor1d([2, 2, 2, 2], 'int32');
        var f = function () {
            tf.grads(function (a, b) {
                var m = tf.pow(b, exponent);
                return tf.sum(m);
            })([a, b]);
        };
        expect(f).toThrowError();
    });
    it('does not error if irrelevant (pruned) ops are missing grads', function () {
        var a = tf.tensor1d([true, true], 'bool');
        var b = tf.tensor1d([false, true], 'bool');
        var da = tf.grad(function (a) {
            // Logical has no gradients, but it is irrelevant.
            a.logicalAnd(b);
            return a.sum();
        })(a);
        test_util_1.expectArraysClose(da, [1, 1]);
    });
    it('errors if relevant ops are missing grads', function () {
        var a = tf.tensor1d([true, true], 'bool');
        var b = tf.tensor1d([false, true], 'bool');
        var dfda = tf.grad(function (a) {
            // Logical has no gradients, but it's relevant to the output.
            return a.logicalAnd(b);
        });
        expect(function () { return dfda(a); }).toThrowError();
    });
    it('works with asType', function () {
        var a = tf.tensor2d([1, 2, 3, 4], [2, 2], 'int32');
        var exponent = tf.tensor2d([2, 2, 2, 2], [2, 2], 'int32');
        var da = tf.grad(function (a) {
            var b = a.toFloat();
            var m = tf.pow(b, exponent);
            return tf.sum(m);
        })(a);
        expect(da.shape).toEqual([2, 2]);
        expect(da.dtype).toEqual('float32');
        test_util_1.expectArraysClose(da, [2, 4, 6, 8]);
    });
    it('asType outside of tf.grads() throws error', function () {
        var a = tf.tensor2d([1, 2, 3, 4], [2, 2], 'int32');
        var b = a.toFloat();
        var exponent = tf.tensor2d([2, 2, 2, 2], [2, 2], 'int32');
        var f = function () {
            tf.grad(function (a) {
                var m = tf.pow(b, exponent);
                return tf.sum(m);
            })(a);
        };
        expect(f).toThrowError();
    });
    it('saves tensors from the forward pass as expected', function () {
        var x = tf.scalar(1).variable();
        var optimizer = tf.train.sgd(0.1);
        optimizer.minimize(function () {
            var y = x.square();
            var z = y.square();
            y.dispose();
            return z;
        });
    });
    it('custom ops do not leak', function () {
        var before = tf.memory().numTensors;
        var x = tf.softmax([1, 2, 3, 4]);
        x.dispose();
        var now = tf.memory().numTensors;
        expect(now).toBe(before);
    });
});
jasmine_util_1.describeWithFlags('valueAndGradients', jasmine_util_1.ALL_ENVS, function () {
    it('matmul + relu', function () {
        var a = tf.tensor2d([-1, 2, -3, 10, -20, 30], [2, 3]);
        var b = tf.tensor2d([2, -3, 4, -1, 2, -3], [3, 2]);
        var _a = tf.valueAndGrads(function (a, b) {
            // m = dot(a, b)
            // y = relu(m)
            // e = sum(y)
            var m = tf.matMul(a, b);
            var y = tf.relu(m);
            return tf.sum(y);
        })([a, b]), value = _a.value, grads = _a.grads;
        test_util_1.expectArraysClose(value, 10);
        // de/dy = 1
        // dy/dm = step(m)
        // de/dm = de/dy * dy/dm = step(m)
        var dedm = tf.step(tf.matMul(a, b));
        var da = grads[0], db = grads[1];
        // de/da = dot(de/dy, bT)
        var transposeA = false;
        var transposeB = true;
        test_util_1.expectArraysClose(da, tf.matMul(dedm, b, transposeA, transposeB));
        // de/db = dot(aT, de/dy)
        transposeA = true;
        transposeB = false;
        test_util_1.expectArraysClose(db, tf.matMul(a, dedm, transposeA, transposeB));
    });
    it('matmul + relu + inner tidy', function () {
        var a = tf.tensor2d([-1, 2, -3, 10, -20, 30], [2, 3]);
        var b = tf.tensor2d([2, -3, 4, -1, 2, -3], [3, 2]);
        var _a = tf.valueAndGrads(function (a, b) {
            // m = dot(a, b)
            // y = relu(m)
            // e = sum(y)
            var m = tf.matMul(a, b);
            return tf.tidy(function () {
                var y = tf.relu(m);
                return tf.sum(y);
            });
        })([a, b]), value = _a.value, grads = _a.grads;
        test_util_1.expectArraysClose(value, 10);
        // de/dy = 1
        // dy/dm = step(m)
        // de/dm = de/dy * dy/dm = step(m)
        var dedm = tf.step(tf.matMul(a, b));
        var da = grads[0], db = grads[1];
        // de/da = dot(de/dy, bT)
        var transposeA = false;
        var transposeB = true;
        test_util_1.expectArraysClose(da, tf.matMul(dedm, b, transposeA, transposeB));
        // de/db = dot(aT, de/dy)
        transposeA = true;
        transposeB = false;
        test_util_1.expectArraysClose(db, tf.matMul(a, dedm, transposeA, transposeB));
    });
});
jasmine_util_1.describeWithFlags('higher-order gradients', jasmine_util_1.ALL_ENVS, function () {
    it('grad(grad(f))', function () {
        var x = tf.tensor1d([.1, .2]);
        var before = tf.memory().numTensors;
        var gradgrad = tf.grad(tf.grad(function (x) { return x.mul(x).mul(x); }));
        var result = gradgrad(x);
        expect(tf.memory().numTensors).toBe(before + 1);
        test_util_1.expectArraysClose(result, [.6, 1.2]);
    });
    it('grad(grad(x^2))', function () {
        var x = tf.scalar(3);
        var gradgrad = tf.grad(tf.grad(function (x) { return x.square(); }));
        var result = gradgrad(x);
        // grad(grad(x^2)) = grad(2x) = 2
        test_util_1.expectArraysClose(result, [2]);
    });
    it('grads(grads(f))', function () {
        var grads = tf.grads(function (x) { return x.mul(x).mul(x); });
        var gradsgrads = tf.grads(function (x) { return grads([x])[0]; });
        var result = gradsgrads([tf.tensor1d([.1, .2])]);
        test_util_1.expectArraysClose(result[0], [.6, 1.2]);
    });
});
jasmine_util_1.describeWithFlags('customGradient', jasmine_util_1.ALL_ENVS, function () {
    it('basic', function () {
        var a = tf.scalar(3);
        var b = tf.scalar(2, 'int32');
        var dy = tf.scalar(4);
        var customPow = tf.customGrad(function (a) {
            var value = tf.pow(a, b);
            var gradFunc = function (dy) { return dy.mul(tf.scalar(0.1)); };
            return { value: value, gradFunc: gradFunc };
        });
        var _a = tf.valueAndGrad(function (a) { return customPow(a); })(a, dy), value = _a.value, grad = _a.grad;
        expect(value.shape).toEqual(a.shape);
        test_util_1.expectArraysClose(value, [9]);
        expect(grad.shape).toEqual(a.shape);
        test_util_1.expectArraysClose(grad, [.4]);
    });
    it('second order derivative through customGradient', function () {
        var a = tf.scalar(3);
        var b = tf.scalar(2, 'int32');
        var dy = tf.scalar(5);
        var customPow = tf.customGrad(function (a, save) {
            var value = tf.pow(a, b);
            save([a]);
            var gradFunc = function (dy, saved) {
                var a = saved[0];
                return dy.mul(a);
            };
            return { value: value, gradFunc: gradFunc };
        });
        var dda = tf.grad(tf.grad(function (a) { return customPow(a); }))(a, dy);
        expect(dda.shape).toEqual(a.shape);
        // First order: dy * a. Second order: dy.
        test_util_1.expectArraysClose(dda, dy);
    });
    it('calling gradient of custom op twice works', function () {
        var customOp = tf.customGrad(function (x, save) {
            // Override gradient of our custom x ^ 2 op to be dy * abs(x);
            save([x]);
            return {
                value: x.square(),
                gradFunc: function (dy, saved) {
                    var x = saved[0];
                    return dy.mul(x.abs());
                }
            };
        });
        var x = tf.tensor1d([-1, -2, 3]);
        var grad = tf.grad(function (x) { return customOp(x); });
        test_util_1.expectArraysClose(grad(x), [1, 2, 3]);
        test_util_1.expectArraysClose(grad(x), [1, 2, 3]);
    });
});
//# sourceMappingURL=gradients_test.js.map